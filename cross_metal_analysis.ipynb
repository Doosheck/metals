{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484961fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450924c",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load cubic spline interpolated price data for all 4 metals (6 series each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "metals = {\n",
    "    'Cobalt': pd.read_csv('data/ALL_cobalt_prices_cubic_spline.csv', parse_dates=['Date'], index_col='Date'),\n",
    "    'Copper': pd.read_csv('data/ALL_copper_prices_cubic_spline.csv', parse_dates=['Date'], index_col='Date'),\n",
    "    'Lithium': pd.read_csv('data/ALL_lithium_prices_cubic_spline.csv', parse_dates=['Date'], index_col='Date'),\n",
    "    'Nickel': pd.read_csv('data/ALL_nickel_prices_cubic_spline.csv', parse_dates=['Date'], index_col='Date')\n",
    "}\n",
    "\n",
    "# Display basic info\n",
    "for metal, df in metals.items():\n",
    "    print(f\"{metal}: {df.shape[0]} rows, {df.shape[1]} series\")\n",
    "    print(f\"  Date range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"  Columns: {', '.join(df.columns)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d09221",
   "metadata": {},
   "source": [
    "## 2. Compute Returns\n",
    "\n",
    "Calculate regular returns (percent change) for all price series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert prices to returns for all metals\n",
    "metals_returns = {}\n",
    "\n",
    "for metal, df in metals.items():\n",
    "    # Calculate returns: (price_t - price_t-1) / price_t-1\n",
    "    returns = df.pct_change()\n",
    "    metals_returns[metal] = returns\n",
    "    \n",
    "    print(f\"{metal} returns:\")\n",
    "    print(f\"  Shape: {returns.shape}\")\n",
    "    print(f\"  Mean return range: {returns.mean().min():.6f} to {returns.mean().max():.6f}\")\n",
    "    print(f\"  Std dev range: {returns.std().min():.4f} to {returns.std().max():.4f}\")\n",
    "    print()\n",
    "\n",
    "# Update the metals dictionary to use returns\n",
    "metals = metals_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ab1a9",
   "metadata": {},
   "source": [
    "## 3. Common Timeframe Identification\n",
    "\n",
    "Find the overlapping period where all 24 series have valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes\n",
    "all_series = pd.concat([df.add_prefix(f'{metal}_') for metal, df in metals.items()], axis=1)\n",
    "\n",
    "# Exclude LISAME series\n",
    "lisame_cols = [col for col in all_series.columns if 'LISAME' in col]\n",
    "if lisame_cols:\n",
    "    print(f\"Excluding LISAME series: {lisame_cols}\")\n",
    "    all_series = all_series.drop(columns=lisame_cols)\n",
    "\n",
    "print(f\"\\nCombined dataset: {all_series.shape}\")\n",
    "print(f\"Date range before alignment: {all_series.index.min()} to {all_series.index.max()}\")\n",
    "print(f\"\\nMissing values per series:\")\n",
    "print(all_series.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common timeframe with complete data\n",
    "# Strategy: Find the period where all 24 series have non-null values\n",
    "\n",
    "# Count non-null values per date across all series\n",
    "complete_dates = all_series.notna().all(axis=1)\n",
    "complete_data = all_series[complete_dates]\n",
    "\n",
    "if len(complete_data) == 0:\n",
    "    # Fallback: use the intersection of date ranges with most data\n",
    "    print(\"\\nNo dates with all 24 series complete. Finding best overlap...\")\n",
    "    \n",
    "    # For each series, find first and last valid dates\n",
    "    series_ranges = {}\n",
    "    for col in all_series.columns:\n",
    "        valid_data = all_series[col].dropna()\n",
    "        if len(valid_data) > 0:\n",
    "            series_ranges[col] = (valid_data.index.min(), valid_data.index.max())\n",
    "    \n",
    "    # Find the common period (latest start, earliest end)\n",
    "    common_start = max(start for start, end in series_ranges.values())\n",
    "    common_end = min(end for start, end in series_ranges.values())\n",
    "    \n",
    "    print(f\"\\nCommon period: {common_start} to {common_end}\")\n",
    "    \n",
    "    # Extract this period\n",
    "    aligned_data = all_series.loc[common_start:common_end].copy()\n",
    "    \n",
    "    # Check coverage\n",
    "    coverage = aligned_data.notna().sum() / len(aligned_data) * 100\n",
    "    print(f\"\\nData coverage in common period:\")\n",
    "    print(coverage.sort_values(ascending=False))\n",
    "    \n",
    "    # Use only series with >90% coverage\n",
    "    good_series = coverage[coverage > 90].index.tolist()\n",
    "    if len(good_series) < 24:\n",
    "        print(f\"\\nUsing {len(good_series)} series with >90% coverage\")\n",
    "        aligned_data = aligned_data[good_series]\n",
    "    \n",
    "    # Forward fill small gaps (max 5 days)\n",
    "    aligned_data = aligned_data.fillna(method='ffill', limit=5)\n",
    "    \n",
    "    # Drop any remaining rows with NaN\n",
    "    aligned_data = aligned_data.dropna()\n",
    "else:\n",
    "    common_start = complete_data.index.min()\n",
    "    common_end = complete_data.index.max()\n",
    "    aligned_data = complete_data\n",
    "\n",
    "# Exclude weekend days (Saturday=5, Sunday=6)\n",
    "weekdays_only = aligned_data.index.dayofweek < 5\n",
    "aligned_data = aligned_data[weekdays_only]\n",
    "\n",
    "print(f\"\\n✓ Final aligned dataset (weekdays only):\")\n",
    "print(f\"  Period: {aligned_data.index.min()} to {aligned_data.index.max()}\")\n",
    "print(f\"  Duration: {(aligned_data.index.max() - aligned_data.index.min()).days} days\")\n",
    "print(f\"  Observations: {len(aligned_data)} (weekdays only)\")\n",
    "print(f\"  Series: {len(aligned_data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c060e72",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis\n",
    "\n",
    "Compute pairwise correlations across all aligned return series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c76bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "corr_matrix = aligned_data.corr()\n",
    "\n",
    "print(f\"Correlation matrix: {corr_matrix.shape}\")\n",
    "print(f\"\\nCorrelation statistics:\")\n",
    "print(f\"  Mean: {corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].mean():.3f}\")\n",
    "print(f\"  Median: {np.median(corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)]):.3f}\")\n",
    "print(f\"  Min: {corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].min():.3f}\")\n",
    "print(f\"  Max: {corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fe591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize full correlation matrix\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(corr_matrix, cmap='RdYlGn', center=0, vmin=-1, vmax=1,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix: All Metal Return Series', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515e160",
   "metadata": {},
   "source": [
    "## 5. Network Visualization\n",
    "\n",
    "Create a correlation network graph to reveal relationships between metals and series.\n",
    "\n",
    "**Design choices:**\n",
    "- **Nodes**: Each return series\n",
    "- **Node colors**: Color-coded by metal (Cobalt=blue, Copper=orange, Lithium=green, Nickel=purple)\n",
    "- **Edges**: Shown only for correlations > 0.3 to reduce clutter\n",
    "- **Edge thickness**: Proportional to correlation strength\n",
    "- **Layout**: Force-directed layout with community detection to reveal clustering patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383080b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with metadata\n",
    "metal_colors = {\n",
    "    'Cobalt': '#3498db',   # Blue\n",
    "    'Copper': '#e67e22',   # Orange\n",
    "    'Lithium': '#27ae60',  # Green\n",
    "    'Nickel': '#9b59b6'    # Purple\n",
    "}\n",
    "\n",
    "node_colors = []\n",
    "node_labels = {}\n",
    "\n",
    "for col in aligned_data.columns:\n",
    "    # Determine metal from column name\n",
    "    metal = col.split('_')[0]\n",
    "    G.add_node(col, metal=metal)\n",
    "    node_colors.append(metal_colors[metal])\n",
    "    node_labels[col] = col\n",
    "\n",
    "# Add edges for significant correlations (threshold: 0.3)\n",
    "correlation_threshold = 0.3\n",
    "edge_weights = []\n",
    "\n",
    "for i, col1 in enumerate(aligned_data.columns):\n",
    "    for col2 in aligned_data.columns[i+1:]:\n",
    "        corr = corr_matrix.loc[col1, col2]\n",
    "        if abs(corr) > correlation_threshold:\n",
    "            G.add_edge(col1, col2, weight=abs(corr))\n",
    "            edge_weights.append(abs(corr))\n",
    "\n",
    "print(f\"Network statistics:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()} (correlations > {correlation_threshold})\")\n",
    "print(f\"  Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect communities using Louvain method\n",
    "communities = community.greedy_modularity_communities(G, weight='weight')\n",
    "\n",
    "print(f\"\\nCommunity detection:\")\n",
    "print(f\"  Number of communities: {len(communities)}\")\n",
    "for i, comm in enumerate(communities):\n",
    "    metals_in_comm = {}\n",
    "    for node in comm:\n",
    "        metal = node.split('_')[0]\n",
    "        metals_in_comm[metal] = metals_in_comm.get(metal, 0) + 1\n",
    "    print(f\"  Community {i+1}: {len(comm)} nodes - {dict(metals_in_comm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network visualization\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Use spring layout with community structure\n",
    "pos = nx.spring_layout(G, k=2, iterations=50, seed=42, weight='weight')\n",
    "\n",
    "# Draw edges with varying thickness\n",
    "edge_widths = [G[u][v]['weight'] * 3 for u, v in G.edges()]\n",
    "nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.3, edge_color='gray')\n",
    "\n",
    "# Draw nodes colored by metal\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, \n",
    "                       node_size=800, alpha=0.9, linewidths=2, edgecolors='white')\n",
    "\n",
    "# Add legend for metals (no node labels to avoid clutter)\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                              markerfacecolor=color, markersize=15, label=metal)\n",
    "                   for metal, color in metal_colors.items()]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=14, framealpha=0.9)\n",
    "\n",
    "plt.title('Cross-Metal Correlation Network\\n(Edge thickness ∝ correlation strength, correlation > 0.3 shown)',\n",
    "          fontsize=16, pad=20)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a43b5f",
   "metadata": {},
   "source": [
    "## 6. Within-Metal vs Cross-Metal Correlations\n",
    "\n",
    "Analyze correlation patterns within and between metals (based on returns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4bc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate within-metal and cross-metal correlations\n",
    "within_metal_corrs = []\n",
    "cross_metal_corrs = []\n",
    "\n",
    "for i, col1 in enumerate(aligned_data.columns):\n",
    "    metal1 = col1.split('_')[0]\n",
    "    for col2 in aligned_data.columns[i+1:]:\n",
    "        metal2 = col2.split('_')[0]\n",
    "        corr = corr_matrix.loc[col1, col2]\n",
    "        \n",
    "        if metal1 == metal2:\n",
    "            within_metal_corrs.append((metal1, corr))\n",
    "        else:\n",
    "            cross_metal_corrs.append((f\"{metal1}-{metal2}\", corr))\n",
    "\n",
    "print(\"Within-metal correlations:\")\n",
    "print(f\"  Count: {len(within_metal_corrs)}\")\n",
    "print(f\"  Mean: {np.mean([c for _, c in within_metal_corrs]):.3f}\")\n",
    "print(f\"  Median: {np.median([c for _, c in within_metal_corrs]):.3f}\")\n",
    "\n",
    "print(\"\\nCross-metal correlations:\")\n",
    "print(f\"  Count: {len(cross_metal_corrs)}\")\n",
    "print(f\"  Mean: {np.mean([c for _, c in cross_metal_corrs]):.3f}\")\n",
    "print(f\"  Median: {np.median([c for _, c in cross_metal_corrs]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Within-metal\n",
    "for metal in metals.keys():\n",
    "    metal_corrs = [c for m, c in within_metal_corrs if m == metal]\n",
    "    if metal_corrs:\n",
    "        axes[0].hist(metal_corrs, bins=20, alpha=0.6, label=metal, color=metal_colors[metal])\n",
    "\n",
    "axes[0].set_xlabel('Correlation', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Within-Metal Correlations', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].axvline(np.mean([c for _, c in within_metal_corrs]), color='red', \n",
    "                linestyle='--', linewidth=2, label=f'Mean: {np.mean([c for _, c in within_metal_corrs]):.2f}')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Cross-metal\n",
    "axes[1].hist([c for _, c in cross_metal_corrs], bins=30, alpha=0.7, color='steelblue')\n",
    "axes[1].set_xlabel('Correlation', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Cross-Metal Correlations', fontsize=14)\n",
    "axes[1].axvline(np.mean([c for _, c in cross_metal_corrs]), color='red', \n",
    "                linestyle='--', linewidth=2, label=f'Mean: {np.mean([c for _, c in cross_metal_corrs]):.2f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7024f35",
   "metadata": {},
   "source": [
    "## 6. Key Insights\n",
    "\n",
    "**Timeframe:** The analysis uses the common period where all series have sufficient data coverage.\n",
    "\n",
    "**Correlation Patterns:**\n",
    "- Within-metal correlations tend to be higher (series from the same metal move together)\n",
    "- Cross-metal correlations reveal economic relationships between different commodity markets\n",
    "- The network graph reveals natural clustering, with some cross-metal connections indicating shared market drivers\n",
    "\n",
    "**Network Structure:**\n",
    "- Node colors clearly distinguish the 4 metals\n",
    "- Edge thickness shows correlation strength\n",
    "- Community detection may reveal groups of series that move together regardless of metal type\n",
    "- Isolated nodes or clusters suggest series with unique price dynamics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
